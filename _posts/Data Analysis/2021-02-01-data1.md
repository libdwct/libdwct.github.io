---
layout: post
title: "[python] 교차검증을 이용한 iris 데이터 분류"
categories: data analysis
tags: TIL
---
---
## <K 폴드 교차 검증\>
  
K개의 데이터 세트를 만들고, 번갈아가며 K번 만큼 학습과 검증 평가를 반복적으로 수행하는 방법이다. 아래는 sklearn의 KFold 클래스를 이용한 방법이다.

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import KFold
import numpy as np

iris_data = load_iris()
features = iris_data.data
label = iris_data.target
dt_clf = DecisionTreeClassifier(random_state = 156)

kfold = KFold(n_splits = 5)
cv_accuracy = []
print('붓꽃 데이터 세트 크기:', features.shape[0])

n_iter = 0

for train_index, test_index in kfold.split(features):
    X_train, X_test = features[train_index], features[test_index]
    y_train, y_test = label[train_index], label[test_index]
    
    dt_clf.fit(X_train, y_train)
    pred = dt_clf.predict(X_test)
    n_iter += 1
    
    accuracy = np.round(accuracy_score(y_test, pred), 4)
    train_size = X_train.shape[0]
    test_size = X_test.shape[0]
    print('\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 데이터 크기: {3}'
          .format(n_iter, accuracy, train_size, test_size))
    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))
    cv_accuracy.append(accuracy)
    
print('\n## 평균 검증 정확도:', np.mean(cv_accuracy))
```

![kfold result](/assets/img/data_analysis/kfold_result.PNG)

<br/>

---
## <Stratified K 폴드\>


Stratified K 폴드는 불균형한 분포드를 가진 레이블 데이터 집합을 위한 K 폴드 방식이다. 원본 데이터에서 K개의 데이터 세트를 만들 때 레이블 값들이 일정한 분포를 갖도록 해준다.

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import StratifiedKFold
import numpy as np

iris_data = load_iris()
features = iris_data.data
label = iris_data.target

dt_clf = DecisionTreeClassifier(random_state = 156)
skfold = StratifiedKFold(n_splits = 3)
n_iter = 0
cv_accuracy = []

for train_index, test_index in skfold.split(features, label):
    X_train, X_test = features[train_index], features[test_index]
    y_train, y_test = label[train_index], label[test_index]
    dt_clf.fit(X_train, y_train)
    pred = dt_clf.predict(X_test)
    
    n_iter += 1
    accuracy = np.round(accuracy_score(y_test, pred), 4)
    train_size = X_train.shape[0]
    test_size = X_test.shape[0]
    print('\n{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'
         .format(n_iter, accuracy, train_size, test_size))
    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))
    cv_accuracy.append(accuracy)

print('\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))
print('## 평균 검증 정확도:', np.mean(cv_accuracy))
```

![stratifiedfold result](/assets/img/data_analysis/stratified_result.png)

<br/>

---
## <cross_val_score\>
위에서 사용한 KFold, StratifiedKFold로 교차 검증을 수행 했을 때는 for 문을 통해서 train, test 인덱스를 지정해주고 모델 학습 및 예측과 평가를 직접해야된다는 번거로움이 있다.

이러한 일련의 과정을 한꺼번에 수행해 주는 API가 cross_val_score이다.

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score, cross_validate
from sklearn.datasets import load_iris

iris_data = load_iris()
dt_clf = DecisionTreeClassifier(random_state = 156)

data = iris_data.data
label = iris_data.target

scores = cross_val_score(dt_clf, data, label, scoring = 'accuracy', cv = 3)
print('교차 검증별 정확도:', np.round(scores, 4))
print('평균 검증 정확도:', np.round(np.mean(scores), 4))
```

![crossvalidate result](/assets/img/data_analysis/cross_result.jpg)

